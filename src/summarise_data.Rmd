---
title: "Summary of psychological ownership survey answers"
author: "Abigail Edwards and Mikko Arvas"
date: "`r Sys.time()`"
output:
  html_document:
    toc: yes
    theme: united
  pdf_document:
    toc: yes
---


TODO:

- is the null model correct ?

- should some other parameters be set to SEM fitting?

 - https://stackoverflow.com/questions/79444918/why-am-i-getting-dimnamesx-dn-length-of-dimnames-2-not-equal-to-array semPaths does not work for other estimators


```{r setup, include=FALSE}
knitr::opts_chunk$set(
	echo = TRUE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(gtsummary)
library(likert)
library(readxl)
library(here)
library(corrplot)
library(ggstats)
library(lavaan)
library(lavaanPlot)
library(semPlot)
#library(blavaan) #could get to work with this model
#library(manymome) # could have interesting other statistics to look at

# https://github.com/cjvanlissa/worcs
# https://cjvanlissa.github.io/worcs/articles/setup.html
# worcs::check_worcs_installation() 

#install.packages("tinytex", dependencies = TRUE)
#library("tinytex")
#install_tinytex()


# https://cjvanlissa.github.io/worcs/reference/add_preregistration.html which template ? 
# https://github.com/crsh/prereg
```


# Data

## Import

```{r}
# Read real data in 
# file <- here("data/Tulokset - xxxxx.xlsx")
# data <- read_xlsx(file,n_max = XX)
# summary(data)
```

Items
<table>
<tr>
<td></td>
<td> Psychological ownership</td>
</tr>
<tr>
<td>po01</td>
<td>
1. I feel a very high degree of personal ownership of donating blood.
</td>
</tr>
<tr>
<td>po02</td>
<td>
2. I feel like donating blood belongs to me.
</td> </tr>
<tr>
<td>po03</td> <td>
3. I feel like I own donating blood.
</td> </tr>
<tr> <td></td>

<td>
Self-identity
</td> </tr>
<tr>
<td>si01</td>
<td>
1. Donating blood is important to me.
</td> <tr>
<td>si02</td> <td>
2. I am like the kind of person who donates blood.
</td> </tr>
<tr> <td>si03</td> 
<td>
3. Donating blood is an important part of who I am.
</td> </tr>
<tr> <td></td>

<td>
Intention
</td></tr>
<tr><td>it01</td>
<td>
1. I would like to donate blood in the future.
</td>   </tr>
<tr><td>it02</td>
<td>
2. I intend to donate blood in the future.
</td> </tr>
<tr><td>it03</td>

<td>
3. I intend to make more than just a one-off blood donation.
</td></tr>
<tr><td></td>
<td>
Intention to donate for emergency
</td></tr>
<tr><td>ie01</td>
<td>
1. I would be willing to donate blood if I received an urgent callout from the Finnish Red Cross Blood Service.
</td></tr>
<tr><td></td> 
<td>
Antecedents of psychological ownership
</td></tr>
<tr><td></td> 

<td>
Control
</td></tr>
<tr><td>ac01</td>
<td>
1. I have influence over the things that affect me while donating blood.
</td></tr>
<tr><td>ac02</td>
<td>
2. I control the location and scheduling for donating blood.
</td></tr>
<tr><td>ac03</td>
<td>
3. I influence decisions related to my blood donation.
</td></tr>
<tr><td>ac04</td>
<td>
4. In general, I have control over donating blood.
</td></tr>
<tr><td></td>
<td>
Intimate knowledge
</td></tr>
<tr><td>ai01</td>

<td>
1. I am intimately familiar with what is going on with regard to donating blood.
</td></tr>
<tr><td>ai02</td>
<td>
2. I have a depth of knowledge as it relates to donating blood.
</td></tr>
<tr><td>ai03</td>
<td>
3. I have a comprehensive understanding of donating blood.
</td></tr>
<tr><td>ai04</td>
<td>
4. I have a broad understanding of donating blood.
</td></tr>
<tr><td></td>

<td>
Self-Investment
</td></tr>
<tr><td>iv01</td>
<td>
1.	I have invested a major part of myself into donating blood.
</td></tr>
<tr><td>iv02</td>
<td>
2. I have invested a significant amount of my time into donating blood.
</td></tr>
<tr><td>iv03</td>
<td>
3. Overall, I invested a lot into donating blood.
</td></tr>
<tr><td></td>


<td>
Blood donation history
</td></tr>
<tr><td>bd01</td>
<td>
1. Do you believe that you are currently eligible to donate blood [yes, no, unsure]
</td></tr>
<tr><td>bd02</td>
<td>
2. How many times in total have you donated blood at the Finnish Red Cross Blood Service Finland? [select number]
</td></tr>
<tr><td>bd03</td>
<td>
3. How many times in the last two years have you donated at the Finnish Red Cross Blood Service? [select number]
</td></tr>
<tr><td>bd04</td>
<td>
4. When did you last attend a Finnish Red Cross blood donation centre with the intention of donating blood? [select date]
</td></tr>
<tr><td></td>

<td>
Demographics
</td></tr>
<tr><td>de01</td>
<td>1. What is your gender? [man, woman, non-binary, prefer to not disclose, prefer to self-describe (open response)]
</td></tr>
<tr><td>de02</td>
<td>
2. How old are you today? [select number]
</td></tr>
</table>


```{r}
#Make question abbreviations
qabbr <- c(
    str_c("po0",1:3),
    str_c("si0",1:3),
    str_c("it0",1:3),
    str_c("ie0",1),
    str_c("ac0",1:4),
    str_c("ai0",1:4),
    str_c("iv0",1:3),
    str_c("bd0",1:4),
    str_c("de0",1:2)
  )

```


```{r}
#With the simulated data sem fitting with data containing factors is unstable, hence here is data and models from that fit.
datafile <- "workingexample20250303.data.rdata"
workingexample <- TRUE # TRUE for working with presimulated data
fitmodels <- TRUE # FALSE for working with prefitted models
if (workingexample) {
  load(file=here(str_c("results/",datafile)))
}
if (!fitmodels) {
  load(file=here(str_replace(str_c("results/",datafile),"\\.data\\.",".models.")))
  fit.po02ss <- models$fit.po02ss
  fit.po02 <- models$fit.po02
  fit.po03ss <- models$fit.po03ss
  fit.po03 <- models$fit.po03

}


```


## Simulate

All items are scored 1 (strongly disagree) to 7 (strongly agree).

```{r}
if (!workingexample) { # if you have data you set this to false
  n <- 1000
  #source("../../responsesR/R/responses.R")
  #create correlation matrix
  #po 3, si 3,  it 3, ie 1, ac 4,ai 4, in 3 
  R <- matrix(
  #     po          si        it        ie         ac        ai              in
  c( 1 ,0.5,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.5, 1 ,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.5,0.5, 1 ,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2, 1 ,0.5,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.5, 1 ,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.5,0.5, 1 ,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2, 1 ,0.5,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.5, 1 ,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.5,0.5, 1 ,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2, 1 ,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2, 1 ,0.5,0.5,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5, 1 ,0.5,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5,0.5, 1 ,0.5,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5,0.5,0.5, 1 ,0.2,0.2,0.2,0.2,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2, 1 ,0.5,0.5,0.5,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5, 1 ,0.5,0.5,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5,0.5, 1 ,0.5,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5,0.5,0.5, 1 ,0.2,0.2,0.2,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2, 1 ,0.5,0.5,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5, 1 ,0.5,
    0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.2,0.5,0.5, 1 
    # bd and de are different
    )
  , nrow=21)
    # if you have problems name the columns and rows here
  rownames(R) <- qabbr[1:21]
  colnames(R) <- qabbr[1:21]
  corrplot(R)
  # Only correlations between latents 
}
```




```{r}
#simulate data with responsesR::get_responses
if (!workingexample) {
library(responsesR)
  
  data_likert_7<- get_responses(n = n,
                K = 7,
                mu = rep(1,nrow(R)),
                gamma1 = 0.1,
                sd = 1,
                R=R
  )
  
  de02 <- round(rnorm(n=n,mean=40,sd =10)) # age
  #de01<- genLikert(size = n,items = 1, levels=4, location=c(-1)) #gender
  de01 <- get_responses(n = n,
                K = 4,
                mu = -1,
                gamma1 = 0.1,
                sd = 0.3
  )
  de01 <-     
      case_when(
      de01 == 1 ~ "women",
      de01 == 2 ~ "man",
      de01 == 3 ~ "Non-binary/other",
      de01 == 4 ~ "Don't wish to respond")
  #bd01 <-  genLikert(size = n,items = 1, levels=3, location=c(-1))
  bd01 <- get_responses(n = n,
                        K = 3,
                        mu = -1,
                        gamma1 = 0.3,
                        sd = 0.7
  )
  bd01 <- case_when(
    bd01 == 1 ~ "yes",
    bd01 == 2 ~ "no",
    bd01 == 3 ~ "unsure",
  )
  data <- bind_cols(
    data_likert_7,
    bd01,
    bd02 = NA,
    bd03 = NA,
    bd04 = NA,
    de01,
    de02
  )
  #colnames(data) <- qabbr[1:ncol(data)]
  colnames(data) <- qabbr
  data <- data %>% 
    mutate(
      # to have some relationship between latent variables make donation counts and po correlate
       bd02 = 
      #take this from po 
         round(as.numeric(po01)  +  
                 as.numeric(po02)   + 
                 as.numeric(data$po03) +
      # and sex
                 0.3*as.numeric(as.factor(de01))   + 
      #with some noise
                 rnorm(nrow(data),0,4) ),
      #make sure it never goes below 1
      bd02 = ifelse(bd02 < 2 ,1,bd02),
      # and count donation in last two years from it with some noise
      bd03 = round(ceiling(bd02 / 5) + rnorm(nrow(data),0,1)),
      bd03 = ifelse(bd03 < 1 ,1,bd03),
      bd04 = sample(seq(as.Date('2022/01/01'), as.Date('2024/01/01'), by="day"), n, replace = TRUE),
      de02 = ifelse(de02 < 18 ,18,de02),
      de02 = ifelse(de02 > 70 ,70,de02)
    )
  
  
  
  
  save(data, file=here(str_c("results/",datafile)))
  summary(data)
} 

```



## Process

```{r}


f1 <- function (x){
  #as numbers but labelled with words
    x <- factor(
    x,
    #levels = c("Strongly disagree","Disagree","Neutral","Agree","Strongly agree"),
    levels = c(1:7),
    ordered = TRUE
  )
  x
}

data <- data %>% 
  mutate_at(
    vars(
      qabbr[1:21]),
    ~ f1(.) 
    ) %>% 
  mutate(bd04 = as.Date(bd04),
         bd01 = factor(bd01, levels = c("no","unsure","yes"),ordered = TRUE),
         de01 = factor(de01)
         )  




summary(data)
```


# Plot



## Demographics Table 1

```{r}

table1 <-
  tbl_summary(
    data %>% 
      # mutate(
      #   bd01 = as.character(bd01) # this did fix this need to think of something
      # ) %>% 
      rename(
      Gender =  de01,
      Age = de02,
      DonationEligibility = bd01,
      DonationCount = bd02,
      DonationCountLast2years = bd03,
    ),
    include = c(
      Age,
      DonationEligibility,
      DonationCount,
      DonationCountLast2years
      ),
    by =  Gender
    
  ) %>%
  add_n()  # add column with total number of non-missing observations
table1
```



## Age by Gender

```{r}

p <- ggplot(data)
p <- p +  geom_histogram(aes(x=de02),binwidth = 5)
p <- p + facet_wrap(. ~ de01)
p <- p + xlab("Age in years")
p

```



## Psychological ownership


```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^po"))) 
)
```




## Self-identity


```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^si"))) 
)
```


## Intention

```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^it"))) 
)
```


## Intention to donate for emergency

```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^ie"))) 
)
```



## Antecedents of psychological ownership - Control

```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^ac"))) 
)
```

## Antecedents of psychological ownership - Intimate knowledge


```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^ai"))) 
)
```


## Antecedents of psychological ownership - Self-Investment


```{r}
gglikert(
  data %>% 
    select(which(str_detect(colnames(data) ,"^iv"))) 
)
```



# Model


```{r}

library(lavaan)
#library(blavaan) # tidySEM requires blavaan
#library(tidySEM) # https://github.com/yrosseel/lavaan/issues/359 lavaan does not work if tidySEM is loaded.

```


## Confirmatory factor analysis

```{r}
models <- list()

isordered <- data %>%  summarise(across(everything(), ~ is.ordered(.x))) %>%  as.logical() %>% which()
isfactor <- data %>%  summarise(across(everything(), ~ is.factor(.x))) %>%  as.logical() %>% which()

#lavaan does not understand empty factor levels
data.fit <- data %>%
  #lavaan cannot deal with unordered factor with more then 2 levels
  filter(de01 == 'man' | de01 == "women") %>% 
  mutate(
    across(isfactor, ~ fct_drop(.x)
    ) %>% 
      mutate(
        bd04 = as.numeric(bd04), # lavaan cannot handle dates
        bd04 = bd04 / 10^-(2 - str_length(as.numeric(max(bd04)))) # https://groups.google.com/g/lavaan/c/r7w-4HHg5R0 
        #"Your underweight variance seems to be much larger than other variances.  Try dividing it by 10 or 100 to make the SDs more similar across modeled variables." 
        # But this does not seem to necessarily help.
      )
  ) %>% 
  #Original paper used sum scores instead of CFA. Let's add them for comparison
  mutate(
    ss_psycown = as.numeric(po01) + as.numeric(po02) + as.numeric(po03),
    ss_selfid = as.numeric(si01) + as.numeric(si02) + as.numeric(si03),
    ss_intention = as.numeric(it01) + as.numeric(it02) + as.numeric(it03),
    #donation history is on diffent scales, normalise them before summing.
    #others should be positively correlated, but bd04 negatively
    ss_blooddonor = scale(as.numeric(bd02)) 
    + scale(as.numeric(bd01)) 
    + scale(bd03)  
    -scale(bd04) # do we want to include the DATE OF LAST DONATION?
    
  )

# To make bootstrapping run there cannot be any unordered factors
data.fit2 <- data.fit %>% 
  mutate(
    de01 = as.ordered(de01)
  ) %>% # and neither any factors at all
mutate(
  across(everything(),as.numeric)
)  # but this also good for plotting correlations


summary(data.fit)
```


```{r}
corrplot(cor(data.fit2))
```



```{r}
po01.model <- ' po =~ po01 + po02 + po03
                si =~ si01 + si02 + si03
                it =~ it01 + it02 + it03
                ac =~ ac01 + ac02 + ac03 + ac04
                ai =~ ai01 + ai02 + ai03 + ai04 
                iv =~ iv01 + iv02 + iv03
                #bd =~ bd01 + bd02 + bd03 + bd04
                bd =~ bd02 + bd01 + bd03 + bd04 #bd02 is sure correlate positively

'
                
fit.po01.cfa <- cfa(po01.model,  
                    estimator = "WLSMV", #
                    
                    data = data.fit)
fit.po01.cfa
# Minimum function test statistic is chi^2
```


```{r}
lavaan::summary(fit.po01.cfa,standardized = TRUE) # tidySEM is loaded this fails!
#lavaan::summary(fit.po01.cfa) # tidySEM is loaded this fails!

#The estimate is the non-standardised as can be seen from the fact that
#the first item is always 1. Then the standardised are in the "Std" columns.
#"Std.all" is "factor loading" and crude rule if thumb is that abs(Std.all) should be above 0.3
#With simulated data bd04 is just random so it should be smaller than others.
```

```{r}
#lavaan::parameterestimates(fit.po02)
# Check items which correlate poorly with their latent factor
cfastd <- lavaan::standardizedsolution(fit.po01.cfa)
cfastd %>% 
  filter(abs(est.std) < 0.3) %>% 
  select(-z,-se) %>% 
  arrange(abs(est.std)) %>% 
  # Just the loadings
  filter(op != '~1')

```




```{r}
lavaan::fitmeasures(fit.po01.cfa,c("npar","chisq","df","cfi","rmsea","srmr"))
```

https://stats.stackexchange.com/questions/541707/cfa-in-lavaan-wont-converge 
"For the comparative fit indices CFI and TLI, you need at least >.900. For the absolute fit indices RMSEA and SRMR, you should have <.080."
So ones from simulated data look good enough.

```{r , fig.height=20}
lavaanPlot(
  fit.po01.cfa,
   edge_options = list(color = "grey"),
  coefs = TRUE,
  graph_options = list(rankdir = "LR")
           )
```


```{r}
#Make a model with out prespesified correlation structure
fit.po01.cfa.o <- cfa(po01.model,data.fit,orthogonal=TRUE)
round(
  sapply(list(cfa=fit.po01.cfa,cfa.o=fit.po01.cfa.o),
         function(x) fitmeasures(x,c("npar","chisq","df","cfi","rmsea","srmr"))
         )
,3)

#cfa should be better than cfa.o in all measures. cfi and chisq should be bigger, rmsea and srmr smaller in model cfa
```

```{r}
#anova(fit.po01.cfa,fit.po01.cfa.o)
#Error: lavaan->lavTestLRT(): 
#some models (but not all) have scaled test statistics
```



## SEM

### Sum score model

```{r}
#https://stats.stackexchange.com/questions/340857/serial-mediation-in-r-how-to-setup-the-model

# N.B. you need to check that first item is positively correlated with your latent factor
# Otherwise you get opposite direction 

po02ss.model <- ' 
#mediation
ss_psycown ~ a1 *  ss_blooddonor 
ss_selfid ~ a2 * ss_blooddonor + d21 * ss_psycown

#regression
ss_intention ~  de01 + de02 + ie01 +  cp * ss_blooddonor + b1 * ss_psycown + b2 * ss_selfid

ind_eff := a1* d21 * b2 
'

cat(po02ss.model)

```


```{r}


if (fitmodels) {

#https://www.tandfonline.com/doi/full/10.1080/10705511.2021.1877548                
fit.po02ss <- sem(po02ss.model,  
                    estimator = "MLR", # robust diagonally weighted least squares stable and should work with ordered factors
                                 data = data.fit2,
                
                #SHOULD SOME OTHER PARAMETERS BE SET?
                
                #The sem function is a wrapper for the more general lavaan function, but setting the following default options:
                # int.ov.free = TRUE, If FALSE, the intercepts of the observed variables are fixed to zero.
                # int.lv.free = FALSE, If FALSE, the intercepts of the latent variables are fixed to zero.
                auto.fix.first = FALSE, #  If TRUE, the factor loading of the first indicator is set to 1.0 for every latent variable. 
                std.lv = TRUE, 
                # auto.fix.single = TRUE, If TRUE, the residual variance (if included) of an observed indicator is set to zero if it is the only indicator of a latent variable.
                # auto.var = TRUE, If TRUE, the (residual) variances of both observed and latent variables are set free.
                # auto.cov.lv.x = TRUE, If TRUE, the covariances of exogenous latent variables are included in the model and set free.
                # auto.efa = TRUE, 
                # auto.th = TRUE, 
                # auto.delta = TRUE,
                # auto.cov.y = TRUE If TRUE, the covariances of dependent variables (both observed and latent) are included in the model and set free.
                  )


#This is quite unstable. Sometimes it says:
#"lavaan 0.6-19 did NOT end normally after nn iterations"
#and sometimes
#"lavaan 0.6-19 ended normally after nn iterations"
#You need to have enough data n~1000?
#
models[["fit.po02ss"]] <- fit.po02ss
}

lavaan::summary(fit.po02ss,standardized = TRUE)

```

```{r}
varTable(fit.po02ss)
```

IS ie01 a problem? should it be numeric?
IS bd04 a problem? should we reduce its variation by scaling it down?



```{r}
#inspect(fit,what="")
lavaan::inspect(fit.po02ss,"r2")
```



```{r}
lavaan::standardizedsolution(fit.po02ss) %>% select(-label)
# Use standardizedSolution to obtain SEs and test statistics for standardized estimates. 

```

```{r}
lavaan::standardizedsolution(fit.po02ss) %>% select(-label,se,z) %>%  filter(op == '~')
```



```{r}

fit.po02ss.est  <-standardizedSolution(fit.po02ss)
fit.po02ss.est %>% 
  filter(abs(est.std) < 0.3) %>% 
  select(-z,-se) %>% 
  arrange(abs(est.std)) %>% 
  # Just the loadings
  filter(op != '~1')

```



```{r}

labelsforplottingnull <- c(
  "ss_psycown" = "Psychological ownership",
  "ss_selfid"  = "Self-identity",
  "ss_intention" = "Intention",
  "ss_blooddonor" = "Blood donation history"
)

lavaanPlot(
  model=fit.po02ss,  
  coefs = TRUE,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  labels = labelsforplottingnull,

  #In simulated data there should be correlations inside
  # bloodonor, psycown, selfid
  # and between
  # bloodonor, psycown
  # and nothing else
  sig = 0.001
  # if sig is < 0.001 one gets significant correlations
  # also from simulated data elsewhere suggesting that 0.05 is not enough
  
  )
```

```{r}
# Same with standardised coefficients
lavaanPlot(
  model = fit.po02ss, 
   labels = labelsforplottingnull,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  )
```



```{r}
semPlot::semPaths(fit.po02ss)
```


### SEM

```{r}
#https://stats.stackexchange.com/questions/340857/serial-mediation-in-r-how-to-setup-the-model

# N.B. you need to check that first item is positively correlated with your latent factor
# Otherwise you get opposite direction 

po02.model <- ' 
#measurement model
psycown =~ po01 + po02 + po03
selfid =~ si01 + si02 + si03
intention =~ it01 + it02 + it03
#psycown_cont =~ ac01 + ac02 + ac03 + ac04 # these were not used in Edwards23
#psycown_know =~ ai01 + ai02 + ai03 + ai04 # these were not used in Edwards23
blooddonor =~ bd02 + bd01 + bd03 +bd04 # do we want to include the DATE OF LAST DONATION?

#mediation
psycown ~ a1 *  blooddonor
selfid ~ a2 * blooddonor + d21 * psycown

#regression
intention ~  de01 + de02 + ie01 +  cp * blooddonor + b1 * psycown + b2 * selfid
ind_eff := a1* d21 * b2
'

cat(po02.model)

```


```{r}


if (fitmodels) {

fit.po02 <- sem(po02.model,  
                    estimator = "MLR", # robust diagonally weighted least squares stable and should work with ordered factors
                                 data = data.fit2,

                #The sem function is a wrapper for the more general lavaan function, but setting the following default options:
                # int.ov.free = TRUE, If FALSE, the intercepts of the observed variables are fixed to zero.
                # int.lv.free = FALSE, If FALSE, the intercepts of the latent variables are fixed to zero.
                auto.fix.first = FALSE,
                std.lv = TRUE 
                # auto.fix.single = TRUE, If TRUE, the residual variance (if included) of an observed indicator is set to zero if it is the only indicator of a latent variable.
                # auto.var = TRUE, If TRUE, the (residual) variances of both observed and latent variables are set free.
                # auto.cov.lv.x = TRUE, If TRUE, the covariances of exogenous latent variables are included in the model and set free.
                # auto.efa = TRUE, 
                # auto.th = TRUE, 
                # auto.delta = TRUE,
                # auto.cov.y = TRUE If TRUE, the covariances of dependent variables (both observed and latent) are included in the model and set free.
                  )


#This is quite unstable. Sometimes it says:
#"lavaan 0.6-19 did NOT end normally after nn iterations"
#and sometimes
#"lavaan 0.6-19 ended normally after nn iterations"
models[["fit.po02"]] <- fit.po02
}

lavaan::summary(fit.po02,standardized = TRUE)

```

```{r}
varTable(fit.po02)
```

IS ie01 a problem? should it be numeric?
IS bd04 a problem? should we reduce its variation by scaling it down?



```{r}
#inspect(fit,what="")
lavaan::inspect(fit.po02,"r2")
```



```{r}
lavaan::standardizedsolution(fit.po02) %>% select(-label)
# Use standardizedSolution to obtain SEs and test statistics for standardized estimates. 

```

```{r}
lavaan::standardizedsolution(fit.po02) %>% select(-label,se,z) %>%  filter(op == '~')
```



```{r}

fit.po02.est  <-standardizedSolution(fit.po02)
fit.po02.est %>% 
  filter(abs(est.std) < 0.3) %>% 
  select(-z,-se) %>% 
  arrange(abs(est.std)) %>% 
  # Just the loadings
  filter(op != '~1')

```



```{r}

labelsforplotting <- c(
  "psycown" = "Psychological ownership",
  "selfid"  = "Self-identity",
  "intention" = "Intention",
  "blooddonor" = "Blood donation history"
)

lavaanPlot(
  model=fit.po02,  
  coefs = TRUE,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  labels = labelsforplotting,

  #In simulated data there should be correlations inside
  # bloodonor, psycown, selfid
  # and between
  # bloodonor, psycown
  # and nothing else
  sig = 0.001
  # if sig is < 0.001 one gets significant correlations
  # also from simulated data elsewhere suggesting that 0.05 is not enough
  
  )
```

```{r}
# Same with standardised coefficients
lavaanPlot(
  model = fit.po02, 
   labels = labelsforplotting,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  )
```



### Sum score with bootstrapping

```{r}
nBoots <- 1000            

if (fitmodels) {
#fit

# https://groups.google.com/g/lavaan/c/A6KCjXAZl-Q good example code

fit.po03ss <- sem(po02ss.model,  
                    estimator = "ML", # bootstrapping does not work with estimators designed for factors
                    data = data.fit2, # data that is completely numeric
                bootstrap = nBoots,
                se = "boot",
                auto.fix.first = FALSE,
                std.lv = TRUE
                )
models[['fit.po03ss']] <- fit.po03ss
}

lavaan::summary(fit.po03ss,standardized = TRUE)

```



```{r}
lavaanPlot(
  model = fit.po03ss, 
   labels = labelsforplottingnull,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  )


```


```{r}
plotfit  <- semPaths(
  fit.po03ss)
```


```{r}
# HERE
# https://stackoverflow.com/questions/66610253/path-diagram-in-r

plotfit  <- semPaths(
  fit.po03ss,
  DoNotPlot = T,
  what ="std"
  )

#plotfit$Arguments$labels

# plotfit <- semptools::change_node_label(
#   plotfit,
#   list(
#     list(node = "slf",to="Self-\nidentity" ),
#     list(node = "bld",to="Blood\ndonation\nhistory" ),
#     list(node = "int",to="Intention" )
#   ),
#   label.cex = .60,
#   label.scale=F
# )
# plot(plotfit)

```

```{r}
#ggsave(plotfit,filename = "testplot.pdf")
```




```{r}
fit.po03ss.best <- parameterEstimates(fit.po03ss)
fit.po03ss.best %>% select(-se,-z) %>% filter(op == "~")
```



### SEM with bootstrapping

```{r}

if (fitmodels) {
#fit

# https://groups.google.com/g/lavaan/c/A6KCjXAZl-Q good example code

fit.po03 <- sem(po02.model,  
                    estimator = "ML", # bootstrapping does not work with estimators designed for factors
                    data = data.fit2, # data that is completely numeric
                bootstrap = nBoots,
                se = "boot",
                auto.fix.first = FALSE,
                std.lv = TRUE 
                )
models[['fit.po03']] <- fit.po03
}

lavaan::summary(fit.po03,standardized = TRUE)

```



```{r}
lavaanPlot(
  model = fit.po03, 
   labels = labelsforplotting,
  node_options = list(shape = "box", fontname = "Helvetica"), 
  edge_options = list(color = "grey"), 
  coefs = TRUE, 
  stand = TRUE,
  sig=0.001
  )


```

```{r}
fit.po03.best <- parameterEstimates(fit.po03)
fit.po03.best %>% select(-se,-z) %>% filter(op == "~")
```

### SEM with Bayes


```{r}
po02b.model <- ' 
#measurement model
psycown =~ po01 + po02 + po03
selfid =~ si01 + si02 + si03
intention =~ it01 + it02 + it03
blooddonor =~ bd02 + bd01 + bd03 +bd04 

# #mediation
 psycown ~ a1 *  blooddonor
 selfid ~ a2 * blooddonor + d21 * psycown
# 
# #regression
 intention ~  de01 + de02 + ie01 +  cp * blooddonor + b1 * psycown + b2 * selfid
ind_eff := a1* d21 * b2
'

cat(po02.model)

```


```{r}
# this does not
# #blavaan
# #tmp <- as.data.frame(data.fit2)
# fit.po04 <- blavaan(po02b.model,  
#         
#         #data = data.fit2 %>% mutate(across(everything(),jitter)),
#         data = data.fit2,
#         auto.fix.first = FALSE,
#         std.lv = TRUE
# )

```

```{r}

#This works!
# data(HolzingerSwineford1939, package = "lavaan")
# # The Holzinger and Swineford (1939) example
# HS.model <- ' visual  =~ x1 + x2 + x3
#               textual =~ x4 + x5 + x6
#               speed   =~ x7 + x8 + x9 '
# 
# fit <- blavaan(HS.model, data = HolzingerSwineford1939,
#                auto.var = TRUE, auto.fix.first = TRUE,
#                auto.cov.lv.x = TRUE)
# summary(fit)
# coef(fit)

```


## Compare models


```{r}
data.forest  <- fit.po03.best %>% 
  mutate(estmet = "Factor analysis\nbootstrapped") %>%  
  filter(op == "~") %>% 
  bind_rows(
    fit.po02.est %>% mutate(estmet = "Factor analysis") %>% 
      rename(est=est.std) %>% 
      filter(op == "~") 
  ) %>% 
  mutate(
    term = str_c(label,":",lhs,op,rhs)
    ) %>% 
  arrange(estmet, term)

data.forest  <- fit.po03ss.best %>% 
  mutate(estmet = "Sum score\nbootstrapped") %>%  
  filter(op == "~") %>% 
  bind_rows(
    fit.po02ss.est %>% mutate(estmet = "Sum score") %>% 
      rename(est=est.std) %>% 
      filter(op == "~") 
  ) %>% 
  mutate(
    term = str_c(label,":",lhs,op,rhs)
    ) %>% 
  arrange(estmet, term) %>% 
  bind_rows(data.forest) %>% 
  mutate(
    lhs =str_replace_all(lhs,"ss_",""),
    rhs =str_replace_all(rhs,"ss_",""),
    term =str_replace_all(term,"ss_",""),
    estmet = as.factor(estmet),
    hollow_group=factor(if_else(ci.lower<=0 & ci.upper>=0, NA_character_, as.character(estmet)),
                             levels=levels(estmet))
  )
  



pos <- position_nudge(y=as.numeric(as.factor(data.forest$estmet))/5 -0.5) 

data.forest %>% 
  mutate(
    hollow_color = ifelse(ci.lower < 0 & ci.upper > 0, NA, "black")
  ) %>% 
  ggplot(aes(est,xmin=ci.lower,xmax=ci.upper,y=term,fill=I(hollow_color),color=estmet))+
  geom_vline(xintercept=0,color="grey") +
  geom_linerange(position=pos)+
  geom_point(shape=21,size=3,position=pos)+
  scale_fill_discrete(na.value=NA) + 
  labs(x="Standardised effect size",y="Relationship") +
  labs(color="Estimation\n method")


```


```{r}
#From https://github.com/FRCBS/anemia_and_hb_deferral_prediction/blob/5a960498883fcca439d5491aca3a593b3dffea86/src/create_anemia_and_deferral_article_results.Rmd

geom_stripes <- function(df, Variable) {
  geom_rect(data=make_stripes(df, Variable) %>% filter(stripe==1),
            mapping=aes(ymax = as.numeric(Variable) + 0.5,
                        ymin = as.numeric(Variable) - 0.5),
            fill = "gray", xmin=-Inf, xmax=Inf, alpha = 0.5, show.legend = FALSE, colour=NA, inherit.aes = FALSE)
}
geom_stripes2 <- function(df, Variable) {
  geom_rect(data=make_stripes(df, Variable) %>% filter(stripe==1),
            mapping=aes(xmax = as.numeric(Variable) + 0.5,
                        xmin = as.numeric(Variable) - 0.5),
            fill = "gray", ymin=-Inf, ymax=Inf, alpha = 0.5, show.legend = FALSE, colour=NA, inherit.aes = FALSE)
}
# Function to to unify x axis ranges on each row.
# Returns a list of scales that can be passed as a parameter to the ggh4x::facetted_pos_scales function,
# to modify individual panels in a facetted plot
unify_range_by_rows <- function(g) {
  b <- ggplot_build(g)
  L <- length(b$layout$panel_scales_x)
  #cols <- 2  # Where is this information stored? Now I have to handcode the number of columns.
  cols <- n_distinct(b$layout$layout$COL)  # Maybe like this?
  rows <- L / cols
  # Unify ranges of a single facet row
  unify <- function(r2) {
    left <- map_dbl(r2, function(x) x[[1]])  # Left ends of the ranges
    right <- map_dbl(r2, function(x) x[[2]])  # Right ends of the ranges
    u <- c(min(left), max(right))
    u <- rep(list(u), length(left))  # Repeat the same range for each column
    # Change this so that a list is returned
    u
  }
  # Extract limits from each panel
  L <- list()
  for (i in seq(1, rows)) {
    tmp <- b$layout$panel_scales_x
    r <- tmp[seq((i-1)*cols + 1, i*cols)]
    r2 <- map(r, function(x) x$range$range) # each item is numeric vector of length two
    res <- unify(r2)
    L <- append(L, res)
  }
  scales <- map(L, function(r) scale_x_continuous(limits = r))  # Turn list of ranges into a list of scales
  scales
}

stat_stripes <- function(mapping = NULL, data = NULL, geom = "rect",
                    position = "identity", na.rm = FALSE, show.legend = FALSE, 
                    inherit.aes = FALSE, alpha = 0.5, fill="gray", row_sizes = NULL, #group=1,
                    ...) {
  layer(
    stat = StatStripes, data = data, mapping = mapping, geom = geom, 
    position = position, show.legend = show.legend, inherit.aes = inherit.aes,
    check.aes=TRUE, check.param = TRUE,
    params = list(row_sizes=row_sizes, alpha=alpha, fill=fill, group=1, 
                  na.rm = na.rm, ...)
  )
}


tmp <- data.forest %>% 
  rename(
    Estimate = est,
    low = ci.lower,
    high = ci.upper,
    Pretty = estmet,
    Color = estmet,
    
    
  )


# g <- tmp %>%
#   ggplot(aes(x=Estimate, xmin=low, xmax=high, y=Pretty, color=Group, fill=hollow_group))+
#   stat_stripes(aes(stripe=Pretty), #row_sizes=c(Bayes=21, Cox=14), 
#                alpha=0.5, fill="lightgray") +
#   #geom_stripes(coeffs, Pretty) +
#   geom_vline(aes(xintercept=0), color="gray", size=1) +
#   ggstance::geom_linerangeh(position=position_dodge(width=1))+#, size=0.2) +
#   geom_point(#aes(), 
#              #fill=NA, 
#              shape=21,
#              size=1.5,
#              position=position_dodge(width=1))+
#              #key_glyph=ggstance::draw_key_pointrangeh) +
#   labs(x="Estimate", y="Standardized variables") +
#   #labs(x="Hazard ratio", y="Standardized variables") +
#   # facet_grid(#model ~ phenotype,
#   #            rows = vars(model), cols = vars(phenotype),
#   #            labeller = labeller(phenotype = pheno_names),
#   #            scales = "free", space = "free", shrink=TRUE, drop=FALSE) +
#   # scale_colour_manual(values = cohort_colors[mygroups],
#   #                     labels = cohort_names[mygroups],
#   #                     breaks = mygroups, na.value = NA, drop=FALSE) +
#   # scale_fill_manual(guide="none",
#   #                   values = cohort_colors[mygroups],
#   #                     labels = cohort_names[mygroups], na.value = NA, drop=FALSE) +
#   guides(color = guide_legend(override.aes = list(shape = 16))) +
#   #scale_x_log10() +
#   scale_y_discrete() +  # !!!!! This is important. Solves the problem with position_dodge2 and the order of rect and pointrange geoms !!!!!!
#                          # Otherwise following error results: Error: Discrete value supplied to continuous scale
#   theme(legend.position="bottom",    
#         panel.grid.major.y = element_blank(),
#         panel.grid.minor.y = element_blank())
# 
# # Same xlims in both facets
# scales2 <- unify_range_by_rows(g)
# gg <- g + ggh4x::facetted_pos_scales(scales2)
# 
# # if (save_figs) {
# #   filename <- sprintf("%s/pdf/facet_forest.pdf", result_base)
# #   ggsave(filename=filename, plot=gg, width = 180, height = 180, units="mm", dpi=300, scale=1.0, device="pdf")
# # }
# gg
# 

```



```{r}

round(
  sapply(list(SS=fit.po02ss,SSB=fit.po03ss,FA=fit.po02,FAB=fit.po03 ),
         function(x) fitmeasures(x,c("chisq","df","cfi","rmsea","srmr"))
         )
,3)

```

According to https://easystats.github.io/effectsize/reference/interpret_gfi.html


"For structural equation models (SEM), Kline (2015) suggests that at a minimum the following indices should be reported: The model chi-square, the RMSEA, the CFI and the SRMR."

chisq, Chi-squared, larger is better

cfi Comparative Fit Index, "It should be > .96" , higher is better

rmsea Root Mean Square Error of Approximation, "should be < .08", smaller is better

srmr Standardized Root Mean Square Residual, "Should be < .08", smaller is better



```{r}
if (fitmodels) {
  save(models,file=here(str_replace(str_c("results/",datafile),"\\.data\\.",".models.")))
}
```

